# Neural Networks

## eXplainable AI (XAI)
XAI refers to a branch of AI that aims to create models and algorithms that are transparent, understandable, and interpretable by human users. In many cases, deep learning models are assumed to be black-box models, whose inputs and operations are not visible to the user or another interested party. To explain the decision-making process of AI models and secure the reliability of AI models, XAI can be utilized to build systems that can provide clear explanations for their decision-making process, thus enabling users to trust and use AI-powered solutions more effectively. This is particularly important for high-stakes applications such as healthcare, finance, and criminal justice, where the consequences of AI-based decisions can be significant. 

XAI methods include techniques such as visualizations, decision trees, and attention-based models. In this course, we are going to use a class activation map (CAM) which provides a visual explanation of the regions in an image that a deep neural network is focusing on to make its predictions. The CAM is a heatmap that highlights the important regions in the image that are contributing to the model's predictions. It allows users to see which regions of an image are most relevant to the model's decision, providing a more intuitive understanding of the model's workings. In the uploaded code, a CNN model is trained for the classification of cats vs dogs and CAM will be drawn to explain the trained CNN model.

## Author
Bogyeong Suh
